Perspectives on Medical Education EYE OPENER

The CSTAR Model: AI and Narrative Medicine in Medical Education
Yang Li, Cuili Ma, Keren Wang
Department of Breast Surgery, China-Japan Union Hospital of Jilin University, Changchun, China

ABSTRACT: 
Large Language Models (LLMs) are reshaping clinical medical education, yet conventional virtual case simulations remain constrained by reductionist biological frameworks that neglect the psychosocial dimensions and narrative complexity of authentic clinical practice. This paper introduces the CSTAR model—Case, Story, Test, Act, Rate—an innovative framework that operationalizes Narrative Medicine principles within AI-driven virtual case-based learning. By structuring virtual encounters around patient stories into virtual encounters alongside disease-specific data, CSTAR bridges the gap between biomedical reductionism and holistic clinical reasoning. Unlike static simulations, CSTAR constructs a iterative learning cycle: "Case" generates structured, guideline-aligned medical data; "Story" dynamically crafts socioeconomic and psychological patient backstories to foster humanistic care alongside technical competence (the model’s defining innovation); "Test" delivers contextually personalized assessments; "Act" enables immersive real-time role-play with AI-simulated patients; and "Rate" provides multidimensional feedback on diagnostic reasoning. Exemplified in breast surgery and rheumatology education, the model enhances learner engagement via dynamic interactions, reduces reliance on scarce clinical cases, and minimizes ethical risks—empowering educators to evolve into curriculum designers. We further explore the imminent integration of Multimodal LLMs (MLLMs) for enhanced sensory fidelity, including generated medical imaging and dynamic patient behaviors. Ultimately, CSTAR offers a sustainable, open-access pathway to broaden access to medical education, strengthening the translation of theoretical knowledge into patient-centered clinical practice.


Artificial intelligence is transforming medical education. Large Language Models (LLMs) now enable new forms of simulated clinical practice, yet most virtual cases remain fixated on biological data, neglecting the psychosocial complexity of real patient care. Learners master diagnostic algorithms but graduate ill-equipped to navigate the anxiety, poverty, and uncertainty that shape actual clinical encounters. 

Narrative Medicine—attention to patients' illness stories—offers a bridge between clinical facts and humanistic care[1]. Yet digital learning environments systematically exclude this dimension, prioritizing mechanical precision over compassionate presence[2]. The result: a generation of learners trained in biological mastery but untested in humanistic engagement[3].

We introduce CSTAR—Case, Story, Test, Act, Rate—a framework that uses LLMs to embed Narrative Medicine within virtual simulation. Unlike static cases, CSTAR generates dynamic patient backstories: learners must navigate not only biology but biography. The model creates bidirectional encounters where AI patients respond to empathic (or dismissive) communication, making humanistic reasoning visible and trainable. As AI capabilities expand, the critical question is whether we will use these tools to automate biomedical reductionism—or finally render holistic care teachable at scale.


The CSTAR Framework
CSTAR uses Large Language Models to generate dynamic virtual patient cases through five components: Case, Story, Test, Act, and Rate. Unlike static simulations, the framework creates encounters where biological data and patient narratives evolve together, enabling learners to practice both technical and humanistic skills.

Case: Dynamic Data
The Case component generates structured medical records in real time, aligned with curricular goals and clinical documentation standards[4]. Patient demographics, chief complaints, histories, and findings are produced dynamically rather than drawn from fixed banks.
* Structured yet Flexibility. The LLM follows clinical documentation norms while allowing educators to adjust parameters for varied presentations.
* Role Shift for Educators. Teachers move from manual case-writing to prompt design—crafting instructions that guide the LLM to generate cases with specific clinical features and appropriate complexity[5].
* Domain Specificity. Cases can be targeted to particular fields (e.g., breast surgery or rheumatology), establishing the biological foundation for subsequent narrative development.

Story: Patient Narratives
Story is CSTAR's central innovation. The LLM generates patient backstories—life circumstances, emotional states, and social determinants of health—that contextualize the biological data. This ensures learners encounter not just disease, but illness as lived experience.
* Narrative Competence. Backstories require learners to integrate psychosocial understanding with clinical reasoning, making empathy a measurable skill rather than an abstract ideal[6,7].
* Variability. Identical pathologies appear in different life contexts, creating diverse diagnostic challenges that mirror real-world unpredictability.
* Values Integration. Narratives provide natural entry points for discussing ethical dilemmas, professional values, and the social contexts of care.

Test: Contextualized Assessment
Test generates evaluation items directly from case parameters and patient stories, ensuring questions reflect the specific context rather than generic templates.
* Contextual Validity. Questions embed narrative details, assessing analytical reasoning rather than memorization.
* Quality Control. Educators set generation criteria, with optional expert review or automated validation to ensure clinical relevance and alignment with learning objectives.

Act: Clinical Encounters
Act uses LLM role-play to create real-time diagnostic interviews[4,8]. The virtual patient responds based on their medical profile and backstory, producing conversations that include uncertainty, emotion, and ambiguity—mirroring authentic clinical communication.
* Interaction Fidelity. The patient exhibits specific communication patterns derived from their narrative context.
* Emotional Realism. Detailed backstories enable responses that reflect the psychological and social dimensions of illness, not just symptom reports.

Rate: Integrated Feedback
Rate evaluates performance across two modes: written tests and simulated consultations.
* Outcome Assessment. Immediate feedback on diagnostic accuracy and treatment choices.
* Process Analysis. The system tracks how learners gather information, form hypotheses, and navigate consultations—revealing reasoning patterns, not just final answers.
* Instructional Insight. Analysis of interaction logs helps educators identify common misconceptions and adjust teaching accordingly.


Educators, Learners, and AI

Redefining the Educator's Role
In CSTAR, educators shift from writing cases to designing them[9]. Traditionally, creating virtual patients demanded hours of manual work, limiting variety and freshness. With LLM support, instructors define core clinical parameters—disease features, narrative boundaries, difficulty levels—then guide the model to generate diverse, evolving scenarios.

Educators adjust generation settings to control complexity, ensuring no two encounters are identical—mirroring real clinical practice. The result mirrors real clinical practice: unpredictable, varied, and demanding adaptive reasoning rather than pattern matching.

Engaging the Learner
Traditional self-directed study often reduces to memorization drills, leading to disengagement[10]. CSTAR reframes learning as active exploration. Through multi-turn conversations with virtual patients (Act), learners navigate incomplete information, patient anxiety, and unexpected revelations—developing clinical intuition through practice rather than memorization.

The model's narrative variability (Story) ensures learners cannot rely on pattern recognition. Each encounter demands fresh reasoning, mirroring the uncertainty of actual practice. This approach resonates with digitally native students, fostering motivation by making the learning process itself intellectually challenging[8]. Diagnostic reasoning emerges through dynamic interaction with patients who respond based on their unique backstories, not from static case banks.

Learning from Data
CSTAR captures process data—how learners ask questions, form hypotheses, and navigate consultations—creating detailed profiles of reasoning patterns[10]. Unlike traditional exams that only record final answers, this reveals the thinking behind decisions.

Feedback operates in two directions. Learners receive personalized guidance based on their interaction patterns, while educators use aggregated data to identify common errors and adjust case design. By spotting systematic mistakes in clinical reasoning, instructors can generate targeted follow-up cases. In this environment, educator, learner, and system continuously adapt: cases evolve based on student needs, and teaching strategies refine based on observed patterns.


Trust, Access, and Teaching
CSTAR addresses three practical barriers to AI adoption in medical education: ensuring clinical accuracy, enabling broad access, and preserving teaching value. Rather than treating these as technical problems, the framework embeds human judgment at every stage—keeping educators central to case design and validation.

Ensuring Accuracy
LLM-generated medical content risks errors or fabrications[11,12]. CSTAR addresses this through structured human oversight rather than unsupervised automation.
* Guided Generation, Expert Review. Prompts first direct the model to align with clinical guidelines. Then faculty review critical diagnostic and therapeutic elements in generated cases. This ensures AI accelerates drafting while clinicians retain final authority over content validity.
* Ethical Integration. Human oversight maintains a necessary barrier between algorithmic output and patient care standards. By keeping educators responsible for final case validation, CSTAR balances efficiency with the safety requirements of medical training—ensuring that virtual patients remain clinically credible vehicles for narrative learning.

Enabling Access
Commercial virtual simulation software often requires prohibitive investment, creating inequities between well-resourced and under-resourced institutions. CSTAR challenges this through open design[9].
* Lightweight Architecture. Built on open-source frameworks and standard web protocols, the platform requires no specialized hardware or million-dollar licenses. This demonstrates that high-quality virtual case platforms can operate at significantly lower cost than commercial alternatives.
* Educator Control. The system enables clinical teachers—regardless of technical background—to customize cases through simple prompt refinement. By removing proprietary barriers, CSTAR extends AI-enhanced narrative medicine to remote or resource-limited settings, aligning technological innovation with educational equity.

Preserving Teaching Value
Discussions of AI often center on efficiency, but CSTAR prioritizes impact on educators. Rather than diminishing teaching roles, the model redirects faculty expertise toward higher-value activities.
* From Drafting to Design. AI handles initial case composition, freeing educators from repetitive writing. Faculty then focus on refining patient backstories (Story) and shaping interactive learning strategies—activities that demand clinical wisdom and pedagogical creativity.
* Mentorship Renewed. By automating mechanical tasks, CSTAR enables educators to serve as guides between virtual simulation and clinical reality. This repositions teaching as mentorship: fostering learner reflection on both technical decisions and humanistic engagement with patient narratives.


Future Directions: Richer Patient Encounters
CSTAR currently uses text to create virtual patient encounters. Yet clinical practice involves more than words: physicians observe facial expressions, hear vocal cues, and interpret imaging. Emerging Multimodal Large Language Models (MLLMs)—which process text, images, and audio—offer opportunities to enrich these simulations. The goal is not technical spectacle, but deeper narrative engagement: helping learners recognize how a patient's appearance, voice, and test results together tell the story of illness.

Integrating Visual Data
Current virtual cases often lack imaging, forcing learners to rely solely on text descriptions. MLLMs could generate relevant visual evidence—ultrasound images, lab reports, ECGs—within the narrative flow of a case[13,14].
* Contextual Imaging. Rather than viewing stock photos, learners could receive imaging results that match the specific patient's story: a breast ultrasound showing features consistent with the described history, or a chest X-ray revealing the pneumonia suggested by examination findings. This requires learners to correlate visual findings with narrative context, not just recognize patterns.
* Active Investigation. Visual data would appear as it does in practice: requested, awaited, and interpreted. Students must decide what to order, consider timing, and integrate results into the evolving patient story—making diagnostic reasoning a dynamic process rather than a given.

Adding Voice and Presence
Much clinical information lies beyond words: tone, pace, silence, gesture. Text cannot convey a patient's anxious hesitation or pain-distorted breathing. MLLMs may eventually enable voice and video generation that supports—rather than replaces—the narrative core.
* Vocal Cues. Synthesized voices could reflect patient states described in the backstory: the tentative speech of depression, the rapid cadence of anxiety, the weakness of illness. Learners would practice recognizing emotional states through sound, integrating auditory cues with verbal content.
* Visual Presence. Video generation might show relevant expressions or movements—guarded posture, averted gaze—that align with the patient's narrative context. The aim is not perfect realism, but sufficient cues to prompt empathic inquiry: noticing distress that the patient has not yet named.

Narrative First
As capabilities expand, the risk grows that technical sophistication will overshadow educational purpose. More realistic images and voices should deepen engagement with patient stories, not distract from them. The goal remains constant: helping learners attend to illness as lived experience, whether conveyed through text today or richer media tomorrow.

Even with advanced simulation, CSTAR retains its commitment to narrative medicine. Virtual patients must remain vehicles for understanding human experience, not demonstrations of technical prowess. The measure of success is not how convincingly a system mimics reality, but how effectively it prepares learners to meet actual patients with competence and compassion.


CSTAR in Practice: Two Scenarios
To illustrate how CSTAR transforms virtual cases, we describe two scenarios: a breast surgery encounter emphasizing diagnostic uncertainty, and a rheumatology consultation highlighting chronic illness narrative. These examples show how the same framework adapts to acute and chronic conditions while maintaining narrative focus.

Scenario 1: Breast Surgery—Navigating Uncertainty
A 45-year-old woman presents with a palpable breast mass. In a conventional simulation, learners would receive a preset history leading to a clear diagnosis. CSTAR generates a dynamic encounter:

Case produces structured data: mass characteristics, family history, imaging results. But Story adds narrative depth: the patient delayed seeking care due to fear of cancer after her mother's death, and she has been researching alternative therapies online. Her anxiety manifests as repeated questioning and requests for reassurance.

During Act, the learner must navigate this emotional context while gathering clinical information. The patient responds differently based on the learner's approach: dismissive questioning triggers withdrawal and incomplete disclosure; empathic inquiry elicits fuller history about herbal supplements she has been taking, which affects surgical planning.

Test generates questions that require integrating biological and narrative data: How does her anxiety affect informed consent? How do alternative therapies interact with planned anesthesia? Rate evaluates not only diagnostic accuracy but whether the learner recognized the emotional barriers to care.

This scenario illustrates how CSTAR maintains clinical rigor while making the human dimensions of care visible and trainable.

Scenario 2: Rheumatology—Living with Invisible Illness
A 32-year-old woman presents with fatigue and joint pain. Conventional cases often reduce this to laboratory values and diagnostic criteria. CSTAR constructs a narrative-rich encounter:

Case generates clinical data: elevated inflammatory markers, joint distribution, morning stiffness duration. Story creates a lived experience: she has been dismissed by previous providers as "just stressed," leading to skepticism toward medical authority. Her symptoms forced her to abandon a career in dance, creating grief and identity loss. Financial strain from part-time work affects medication adherence.

Act requires learners to engage with this accumulated medical trauma. The patient tests the learner's credibility: "Are you actually going to listen, or just run tests?" Her responses vary—defensive, hopeful, resigned—based on whether the learner acknowledges her previous experiences before proceeding with examination.

Test includes scenarios where biological knowledge is insufficient: How do you respond when she refuses methotrexate due to fears about side effects she read about online? How do you address the depression screening she initially resents as "another box to check"?

Rate assesses the learner's ability to maintain therapeutic alliance while negotiating treatment goals. Did they recognize the grief beneath the symptom report? Did they adapt communication to her skepticism rather than dismiss it as noncompliance?

This scenario shows how CSTAR makes chronic illness education—often reduced to disease mechanisms—into training for longitudinal, relationship-centered care.

Table 1. Comparison of CSTAR Applications: Breast Surgery vs. Rheumatology
DimensionBreast Surgery ScenarioRheumatology ScenarioCore challengeDiagnostic uncertaintyLongitudinal relationship buildingNarrative focusDecision pressure and fearMedical trauma and identity lossKey skillRapid trust establishmentRepairing therapeutic allianceTime frameAcute, single encounterChronic, longitudinal care
Common Threads, Distinct Challenges
Both scenarios illustrate CSTAR's core innovation: embedding narrative within clinical structure. Yet they reveal different demands (Table 1). The breast case emphasizes diagnostic uncertainty management—learners must tolerate ambiguity while building trust. The rheumatology case highlights longitudinal relationship building—learners navigate accumulated patient experience and systemic barriers to care.

The framework adapts to these differences through Story generation. Acute cases require backstories that explain presentation delays and decision pressures; chronic cases need narratives of identity change, medical trauma, and social determinants over time. Both require learners to integrate biological and psychosocial reasoning, but the integration looks different: rapid calibration in surgery, sustained negotiation in rheumatology.

These examples suggest how CSTAR might scale across specialties—not by standardizing content, but by standardizing the narrative-clinical integration that each field requires.


Looking Ahead
CSTAR offers more than a technical tool. It proposes an answer to how medical education might preserve humanistic care as AI becomes ubiquitous. The framework's value lies not in replacing educator judgment but in making narrative-based teaching scalable. By embedding patient stories within structured cases, it demonstrates that technological efficiency and clinical compassion need not be opposed. The question is no longer whether AI belongs in medical training, but whether we will use it to teach what matters most.

Realizing this vision requires institutional courage. Medical schools must resist the temptation to adopt AI for efficiency alone, instead demanding tools that strengthen narrative competence. This means accepting slower implementation in favor of thoughtful integration—keeping educators central to case design, not sidelined by automation.

It also requires addressing equity. Open-source approaches can prevent AI-enhanced education from becoming a privilege of wealthy institutions. Shared resources—common standards for case quality, collaborative prompt libraries—would extend access without sacrificing local adaptation.

Finally, faculty need support, not surveillance. Digital literacy should be cultivated through community building, not added to promotion checklists. The goal is to help teachers become designers of patient encounters, not competitors with algorithms.

As multimodal capabilities expand—adding voice, image, and gesture to text—the temptation will grow to pursue realism for its own sake. CSTAR's challenge is to use these tools to deepen narrative engagement, not to dazzle with simulation fidelity. The measure of success remains whether learners emerge better prepared to meet actual patients with attention to their stories.

Medical education has long struggled to teach what cannot be easily measured: the recognition of suffering, the negotiation of uncertainty, the moral weight of clinical decisions. AI, thoughtfully deployed, might finally make these learnable at scale[15,16]. That possibility merits the patience this transformation requires.


Reference

1. Charon R. The patient-physician relationship. Narrative medicine: a model for empathy, reflection, profession, and trust. JAMA. 2001;286:1897–902. https://doi.org/10.1001/jama.286.15.1897
2. Shapiro J, Coulehan J, Wear D, Montello M. Medical humanities and their discontents: definitions, critiques, and implications. Acad Med. 2009;84:192–8. https://doi.org/10.1097/ACM.0b013e3181938bca
3. Hurwitz B, Charon R. A narrative future for health care. Lancet. London, England; 2013;381:1886–7. https://doi.org/10.1016/S0140-6736(13)61129-0
4. Kononowicz AA, Woodham LA, Edelbring S, Stathakarou N, Davies D, Saxena N, et al. Virtual Patient Simulations in Health Professions Education: Systematic Review and Meta-Analysis by the Digital Health Education Collaboration. J Med Internet Res. 2019;21:e14676. https://doi.org/10.2196/14676
5. Posel N, Mcgee JB, Fleiszer DM. Twelve tips to support the development of clinical reasoning skills using virtual patient cases. Med Teach. 2015;37:813–8. https://doi.org/10.3109/0142159X.2014.993951
6. Greenhalgh T, Hurwitz B. Narrative based medicine: why study narrative? BMJ. Clinical research ed.; 1999;318:48–50. https://doi.org/10.1136/bmj.318.7175.48
7. Ak K. A conceptual framework for the use of illness narratives in medical education. Academic medicine : journal of the Association of American Medical Colleges [Internet]. Acad Med; 2008 [cited 2026 Feb 11];83. https://doi.org/10.1097/ACM.0b013e3181782e17
8. Consorti F, Mancuso R, Nocioni M, Piccolo A. Efficacy of virtual patients in medical education: A meta-analysis of randomized studies. Computers & Education. 2012;59:1001–8. https://doi.org/10.1016/j.compedu.2012.04.017
9. Masters K. Artificial intelligence in medical education. Med Teach. 2019;41:976–80. https://doi.org/10.1080/0142159X.2019.1595557
10. Cook DA, Hatala R. Validation of educational assessments: a primer for simulation and beyond. Adv Simul (Lond). London, England; 2016;1:31. https://doi.org/10.1186/s41077-016-0033-y
11. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepaño C, et al. Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models. PLOS Digit Health. 2023;2:e0000198. https://doi.org/10.1371/journal.pdig.0000198
12. Gilson A, Safranek CW, Huang T, Socrates V, Chi L, Taylor RA, et al. How Does ChatGPT Perform on the United States Medical Licensing Examination (USMLE)? The Implications of Large Language Models for Medical Education and Knowledge Assessment. JMIR Med Educ. 2023;9:e45312. https://doi.org/10.2196/45312
13. Radford A, Kim JW, Xu T, Brockman G, McLeavey C, Sutskever I. Robust Speech Recognition via Large-Scale Weak Supervision [Internet]. arXiv; 2022 [cited 2026 Feb 11]. https://doi.org/10.48550/arXiv.2212.04356
14. Rombach R, Blattmann A, Lorenz D, Esser P, Ommer B. High-Resolution Image Synthesis with Latent Diffusion Models [Internet]. arXiv; 2022 [cited 2026 Feb 11]. https://doi.org/10.48550/arXiv.2112.10752
15. The potential for artificial intelligence in healthcare. Future Healthcare Journal. Elsevier; 2019;6:94–8. https://doi.org/10.7861/futurehosp.6-2-94
16. AI in health and medicine | Nature Medicine [Internet]. [cited 2026 Feb 11]. https://www.nature.com/articles/s41591-021-01614-0. Accessed 11 Feb 2026

